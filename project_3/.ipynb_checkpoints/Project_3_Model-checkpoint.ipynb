{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae18ad6",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58672da1",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1e30d",
   "metadata": {},
   "source": [
    "There is increased competition in the space for coding bootcamps. Bootcamps such as Hack Reactor, Vertical Institute, Rocket Academy and Le Wagon. If no action is taken, there will be a decline in market share, poor marketing return of investment (ROI), poorer lead generation which means we will not be able to meet the enrollment KPI's.\n",
    "\n",
    "GA marketing is therefore trying to figure out how to better identify the online persona of a bootcamp seeker as opposed to that of a computer science major to aid in targeted advertising.\n",
    "\n",
    "\n",
    "Considering the two topics have quite a bit in common, efforts to further segregate the two targets could yield better advertising ROI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8907d",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67ac19",
   "metadata": {},
   "source": [
    "Due to increased competition in the market for bootcamps. General Assembly has been facing poorer enrollments and they intend to maintain their position as one of the better bootcamps out there.We are team of data scientists that are being tasked by General Assembly to build a model with >90% accuracy that helps to identify between those who are looking for bootcamp style learning vs computer science majors/prospective students based on the words they use online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7a4d8",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98b5ea",
   "metadata": {},
   "source": [
    "| Feature | Type | Dataset | Description|\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| subreddit | Object | cs_major / coding_bootcamp | Subreddit contains the topic of the subreddit in the dataframe. Either cs Major or coding bootcamp|\n",
    "| selftext | Object | cs_major / coding_bootcamp | selftext contains the text or the message of the post written by the end user. |\n",
    "| title | Object | cs_major / coding_bootcamp | title contains the title of the post. |\n",
    "| csMajors | Object | cs_major | csMajors is the topic or also known as the subreddit. csMajors refers to Computer Science Major that universities offers to students. |\n",
    "| coding_bootcamp | Object | coding_bootcamp| coding_bootcamp is the topic or also known as the subreddit. coding_bootamp refers to coding bootcamps that are taken by mid-career switches, companies and students who are interested in upskilling. | \n",
    "| combined_text | Object | cs_major / coding_bootcamp | combined_text is the combined columns of selftext and title. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be28f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, r2_score\n",
    "from sklearn.metrics import  accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5c3ea",
   "metadata": {},
   "source": [
    "### Load CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da600889",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = pd.read_csv('data/cs_major.csv')\n",
    "bc = pd.read_csv('data/coding_bootcamp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeae4b4",
   "metadata": {},
   "source": [
    "Included the new_stopwords found from the EDA to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613e2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stopwords = ['like','im','know','boot','would','camp','looking','got','get','one','back','know']\n",
    "stopwords.extend(new_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10fdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling null values with an empty string\n",
    "cs.fillna('',inplace = True)\n",
    "\n",
    "# combine both title and selftext as a new column\n",
    "cs['combined_text'] = cs['selftext'] + ' ' + cs['title']\n",
    "cs.drop(axis = 1, columns = cs[['selftext', 'title']], inplace = True)\n",
    "\n",
    "#filling null values with an empty string\n",
    "bc.fillna('', inplace = True)\n",
    "\n",
    "#combine both title and selftext as a new column\n",
    "bc['combined_text'] = bc['selftext'] + ' ' + bc['title']\n",
    "bc.drop(axis = 1, columns = bc[['selftext', 'title']], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422fac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to clean text, remove punctuation\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text =  \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    \n",
    "    # apply lemmatize and stopwords exclusion within the same step\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return ' '.join(text)\n",
    "\n",
    "cs['combined_text_clean'] = cs['combined_text'].apply(lambda x: clean_text(x))\n",
    "cs.drop(axis = 1, columns = 'combined_text',inplace = True)\n",
    "\n",
    "\n",
    "bc['combined_text_clean'] = bc['combined_text'].apply(lambda x: clean_text(x))\n",
    "bc.drop(axis = 1, columns = 'combined_text',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5c56e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>combined_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csMajors</td>\n",
       "      <td>recently accepted first job offer starting june previously spoken relocating assistance told ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>csMajors</td>\n",
       "      <td>sed update took month hear cap rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csMajors</td>\n",
       "      <td>wanted make post hopefully inspire people go low ranked school gonna talk advice general thing l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csMajors</td>\n",
       "      <td>renegotiate intern offer try different time fall spring instead summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>csMajors</td>\n",
       "      <td>applied around 200 internship season ended receiving two offer uhgoptum cigna first internship c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  \\\n",
       "0  csMajors   \n",
       "1  csMajors   \n",
       "2  csMajors   \n",
       "3  csMajors   \n",
       "4  csMajors   \n",
       "\n",
       "                                                                                   combined_text_clean  \n",
       "0  recently accepted first job offer starting june previously spoken relocating assistance told ava...  \n",
       "1                                                              sed update took month hear cap rejected  \n",
       "2  wanted make post hopefully inspire people go low ranked school gonna talk advice general thing l...  \n",
       "3                               renegotiate intern offer try different time fall spring instead summer  \n",
       "4  applied around 200 internship season ended receiving two offer uhgoptum cigna first internship c...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b6d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for non vectorised\n",
    "df = pd.concat([cs, bc], axis = 0, ignore_index = True)\n",
    "df[\"subreddit\"] = df[\"subreddit\"].map({'codingbootcamp': 1,\n",
    "                                      'csMajors': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74588f",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a6a83",
   "metadata": {},
   "source": [
    "Here we have split the modelling into the 2 vectorisation methods using GridSearch CV with pipeline. Each pipeline will contain the vectorisation method and a classifier. We will be using TF-IDF and CountVectorisation with N-gram(1,3) for the vectorisation methods. We will be using Multinomial Naive Bayes and Logistic Regression for the classification methods. We hope to find out which pair has the best f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52867830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X, y for train test split\n",
    "X = df['combined_text_clean']\n",
    "y = df['subreddit']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, stratify = y,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea7e74",
   "metadata": {},
   "source": [
    "## TF-IDF Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e8249",
   "metadata": {},
   "source": [
    "### GridSearch and Pipeline (TF-IDF w/N-gram(1,3), Multinomial Naive Bayes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f3d8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce03fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with tf-idf vectorizer and multinomial naive bayes\n",
    "\n",
    "pipe_tvec = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3fdc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for pipeline with tf-idf\n",
    "pipe_tvec_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02e0779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec = GridSearchCV(pipe_tvec, \n",
    "                        param_grid = pipe_tvec_params, \n",
    "                       scoring='f1',\n",
    "                        cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4c95db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': [None, 'english']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_tvec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c06b9169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9330558446063129\n",
      "0.9110032362459547\n"
     ]
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "print(gs_tvec.score(X_train, y_train))\n",
    "# Score model on testing set.\n",
    "print(gs_tvec.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_tvec.best_params_)\n",
    "print(gs_tvec.best_score_)\n",
    "print(gs_tvec.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds_tvec = gs_tvec.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds_tvec)) # 0: CS Major, 1: Coding bootcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1661e",
   "metadata": {},
   "source": [
    "### GridSearch and Pipeline (TF-IDF w/N-gram(1,3), Logistic Regression )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "#instantiate pipeline\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "# selected parameters for pipeline\n",
    "pipe_tvec_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "}\n",
    "# Instantiate GridSearchCV.\n",
    "gs_tvec = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_tvec_params, \n",
    "                  scoring = 'f1',\n",
    "                  cv=5) # 5-fold cross-validation.\n",
    "\n",
    "#fit X,y train into gridsearch\n",
    "gs_tvec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b671f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model on training set.\n",
    "print(gs_tvec.score(X_train, y_train))\n",
    "#score model on test set.\n",
    "print(gs_tvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa837b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_tvec.best_params_)\n",
    "print(gs_tvec.best_score_)\n",
    "print(gs_tvec.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0219b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = gs_tvec.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) # 0: CS Major, 1: Coding bootcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2ca7e",
   "metadata": {},
   "source": [
    "## Count Vectorizer Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f746849",
   "metadata": {},
   "source": [
    "### GridSearch and Pipeline (CountVectorizer w/N-gram(1,3), Multinomial Naive Bayes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X, y for train test split\n",
    "X = df['combined_text_clean']\n",
    "y = df['subreddit']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, stratify = y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30233be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate pipeline\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(ngram_range = (1,3))),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params, \n",
    "                  cv=5) # 5-fold cross-validation.\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f7b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9112500000000001\n",
      "0.9251785714285714\n",
      "0.9079166666666667\n"
     ]
    }
   ],
   "source": [
    "# the best score from GridSearch CV\n",
    "print(gs.best_score_)\n",
    "\n",
    "# Score model on training set.\n",
    "print(gs.score(X_train, y_train))\n",
    "\n",
    "# Score model on testing set.\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9e444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      1200\n",
      "           1       0.90      0.92      0.91      1200\n",
      "\n",
      "    accuracy                           0.91      2400\n",
      "   macro avg       0.91      0.91      0.91      2400\n",
      "weighted avg       0.91      0.91      0.91      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "y_pred = gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) # 0: CS Major, 1: Coding bootcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea3697",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab0135",
   "metadata": {},
   "source": [
    "### GridSearch and Pipeline (CountVectorizer w/ N-gram(1,3), Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da8aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X, y for train test split\n",
    "X = df['combined_text_clean']\n",
    "y = df['subreddit']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, stratify = y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7532e5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(ngram_range=(1, 3))),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(ngram_range = (1,3))),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2),(1,3)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params, \n",
    "                  scoring = 'f1',\n",
    "                  cv=5) # 5-fold cross-validation.\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb7810f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9201746533460197\n",
      "0.9875489149768766\n",
      "0.9153526970954358\n"
     ]
    }
   ],
   "source": [
    "# the best score from GridSearch CV\n",
    "print(gs.best_score_)\n",
    "# Score model on training set.\n",
    "print(gs.score(X_train, y_train))\n",
    "#score model on test set.\n",
    "print(gs.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dad9252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      1200\n",
      "           1       0.91      0.92      0.92      1200\n",
      "\n",
      "    accuracy                           0.92      2400\n",
      "   macro avg       0.92      0.92      0.91      2400\n",
      "weighted avg       0.92      0.92      0.91      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "y_pred = gs.predict(X_test)\n",
    "print(classification_report(y_test, y_pred)) # 0: CS Major, 1: Coding bootcamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91ef22",
   "metadata": {},
   "source": [
    "# Evaluation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4c153",
   "metadata": {},
   "source": [
    "| Vectorizer |Classification Model | Train | Test |\n",
    "|:---|:---|:---|:---\n",
    "| TFIFD | Naive Bayes | 0.93305 | 0.91100 |\n",
    "| TFIFD | Logistic Regression | 0.962240| 0.925879 |\n",
    "| CountVectorizer | Naive Bayes | 0.92517 | 0.90791 |\n",
    "| CountVectorizer | Logistic Regression| 0.98754 | 0.91535 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892c5f4",
   "metadata": {},
   "source": [
    "The train/test scores shows good range and below 0.1 between the train and test scores. The models are decently accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8434c73",
   "metadata": {},
   "source": [
    "| Vectorizer |Classification Model | f1 score|\n",
    "|:---|:---|:---|\n",
    "| TFIFD | Naive Bayes | 0.91 |\n",
    "| TFIFD | Logistic Regression | 0.93 |\n",
    "| CountVectorizer | Naive Bayes | 0.91 | \n",
    "| CountVectorizer | Logistic Regression| 0.92 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62419c66",
   "metadata": {},
   "source": [
    "We have selected the TFIFD / Logistic Regression to be the best performing model with a f1 score of 0.93."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
